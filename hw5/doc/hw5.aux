\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{Exercise 1: Ridge Regression}{1}{section*.1}\protected@file@percent }
\newpmemlabel{^_1}{2}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Comparison of L1, Ridge Regression, Least Squares for different values of $k=1,2,3,5,10,15$. We note that that ridge regression introduces a bias towards the outliers in the data}}{3}{figure.caption.2}\protected@file@percent }
\newpmemlabel{^_2}{4}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Note that Test loss stabilizes around k=5 and increases subsequently, while training loss continues to decrease. We note that $\lambda $=30 registers a higher training loss than $\lambda $=0 as regularization slows down overfitting to training data.}}{5}{figure.caption.3}\protected@file@percent }
\newpmemlabel{^_3}{10}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  Using normalized basis functions. }}{10}{figure.caption.4}\protected@file@percent }
\bibdata{sample-handout}
\bibstyle{plainnat}
\ttl@finishall
\gdef \@abspage@last{11}
